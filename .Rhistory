df <- data
dim(df)
data <- read.csv("~/PycharmProjects/bda_594/BDA594-Group10/cleaned_data.csv", header=TRUE)
View(data)
df <- data
colnames(df)
dim(df)
# remove first column
data <- data[-1]
colnames(data)
########## remove outliers from predictors ##########
# remove temp < 75 or > 108
temp_range <- (75:108)
data <- subset(data, data$temperature %in% temp_range)
# remove resprate > 100 or < 10
resp_rate <- (10:100)
data <- subset(data, data$resprate %in% resp_rate)
# remove O2 state below 60
o2_rate <- (60:1000)
data <- subset(data, data$o2sat %in% o2_rate)
# remove pain levels outside of 0-10 range
pain_range <- (0:10)
data <- subset(data, data$pain %in% pain_range)
# compare descriptive stats before and after
summary(df)
og_data <- df
og_data_dim <- dim(og_data)
og_data_dim
dim(data)
df <- data
og_data_dim
og_data_dim <- dim(og_data[1])
og_data_dim
og_data_dim[1]
og_data_dim <- dim(og_data[,1])
og_data_dim
og_data <- df
og_data_dim <- dim(og_data[,1])
og_data_dim
og_data_dim <- dim(og_data[,0])
og_data_dim
og_data_dim[1]
og_data_dim <- dim(og_data)
data_dim <- dim(data)
og_data_dim[1] - data_dim[1]
data_dim
data_dim[1]
og_data_dim <- og_data_dim[1]
data_dim <- data_dim[1]
og_data_dim
data_dim
data_dim <- dim(data)
data_dim <- data_dim[1]
data_dim
og_data_dim
og_data <- df
og_data_dim <- dim(og_data)
og_data_dim
data <- read.csv("~/PycharmProjects/bda_594/BDA594-Group10/cleaned_data.csv", header=TRUE)
df <- data
colnames(df)
# remove first column
data <- data[-1]
colnames(data)
df <- data
# remove temp < 75 or > 108
temp_range <- (75:108)
data <- subset(data, data$temperature %in% temp_range)
# remove resprate > 100 or < 10
resp_rate <- (10:100)
data <- subset(data, data$resprate %in% resp_rate)
# remove O2 state below 60
o2_rate <- (60:1000)
data <- subset(data, data$o2sat %in% o2_rate)
# remove pain levels outside of 0-10 range
pain_range <- (0:10)
data <- subset(data, data$pain %in% pain_range)
# compare descriptive stats before and after
summary(df)
summary(data)
og_data <- df
og_data_dim <- dim(og_data)
data_dim <- dim(data)
og_data_dim <- og_data_dim[1]
data_dim <- data_dim[1]
og_data_dim
data_dim
og_data_dim - data_dim
dim(df[1]) - dim(data[1])
total_rows = [(dim(df[1]) - dim(data[1])), 1]
total_rows = (dim(df[1]) - dim(data[1])), 1
total_rows = dim(df[1]) - dim(data[1])
total_rows
total_rows <- total_rows[1]
total_rows
## write a new csv file of cleaned dataset
write.csv(r, 'cleaned_data2.csv')
## write a new csv file of cleaned dataset
write.csv('cleaned_data2.csv')
## write a new csv file of cleaned dataset
write.csv(data, 'cleaned_data2.csv')
?write.csv
## write a new csv file of cleaned dataset
write.csv(data, 'cleaned_data2.csv', row.names = FALSE)
table(data)
colnames(df)
?createDataPartition
######### analyses #########
# split data into training and test set
set.seed(199)
trainIndex <- createDataPartition(data$acuity, p = .7, list=F)
d.train <- data[trainIndex]
d.train <- data[trainIndex,]
d.test <- data[-trainIndex,]
dim(d.test)
dim(d.train)
?train
# logistic regression
set.seed(199)
d.log <-  train(data ~ ., data=d.train, method="glm", family="binomial", metric="ROC", trControl=ctrl)
#setup control function for resampling and binary classification performance
#using 10 fold cross validation
ctrl <- trainControl(method = "cv", number=10, summaryFunction=twoClassSummary,
classProbs=T, savePredictions=T) #saving predictions from each resample fold
# logistic regression
set.seed(199)
d.log <-  train(data ~ ., data=d.train, method="glm", family="binomial", metric="ROC", trControl=ctrl)
library(caret)
library(ISLR)
library(pROC)
data(Default)
str(Default)
#these data are unbalanced
d.table<- table(Default$default)
prop.table(d.table) # .03% of cases are postive class
#lets relevel the Default factor so Yes becomes the Positive class by default (Sensitivity)
Default$default <- relevel(Default$default, ref="Yes")
#converting to factors to dummy codes
#including DV because it should be a binary value too
default.dmodel <- dummyVars(~student + balance + income, data=Default, fullRank=T)
Default.d <- as.data.frame(predict(default.dmodel, Default))
Default.d$default <- Default$default #copy back DV
str(Default.d)
#creating test and training set as example
#if dataset is not very big avoid train/test splits high variation
#going use carets partition function to randomly split 70% of training set values
#proportional to class balance
set.seed(199)
trainIndex <- createDataPartition(Default.d$default, p=.7, list=F)
d.train <- Default.d[trainIndex,]
d.test <- Default.d[-trainIndex,]
#setup control function for resampling and binary classification performance
#using 10 fold cross validation
ctrl <- trainControl(method = "cv", number=10, summaryFunction=twoClassSummary,
classProbs=T, savePredictions=T) #saving predictions from each resample fold
##logistic regression
set.seed(199)#ALWAYS USE same SEED ACROSS trains to ensure identical cv folds
d.log <-  train(default ~ ., data=d.train, method="glm", family="binomial", metric="ROC", trControl=ctrl)
summary(d.log)
typeOf(d.train)
type(d.train)
typeof(d.train)
data <- read.csv("~/PycharmProjects/bda_594/BDA594-Group10/cleaned_data.csv", header=TRUE)
df <- data
colnames(df)
dim(df)
# remove first column
data <- data[-1]
colnames(data)
df <- data
########## remove outliers from predictors ##########
# remove temp < 75 or > 108
temp_range <- (75:108)
data <- subset(data, data$temperature %in% temp_range)
# remove resprate > 100 or < 10
resp_rate <- (10:100)
data <- subset(data, data$resprate %in% resp_rate)
# remove O2 state below 60
o2_rate <- (60:1000)
data <- subset(data, data$o2sat %in% o2_rate)
# remove pain levels outside of 0-10 range
pain_range <- (0:10)
data <- subset(data, data$pain %in% pain_range)
# compare descriptive stats before and after
summary(df) # original dataset
summary(data)
total_rows = dim(df[1]) - dim(data[1])
total_rows <- total_rows[1]
total_rows
## write a new csv file of cleaned dataset
#write.csv(data, 'cleaned_data2.csv', row.names = FALSE)
######### analyses #########
# split data into training and test set
# training set = .7
set.seed(199)
trainIndex <- createDataPartition(data$acuity, p = .7, list=F)
d.train <- data[trainIndex,]
d.test <- data[-trainIndex,]
# logistic regression
data <- as.data.frame(data)
set.seed(199)
d.log <-  train(data ~ ., data=d.train, method="glm", family="binomial", metric="ROC", trControl=ctrl)
typeof
typeof(data)
?train
# checking for imbalances
d.table<- table(data$acuity)
d.table
prop.table(d.table)
#lets relevel the Default factor so Yes becomes the Positive class by default (Sensitivity)
data$acuity<- relevel(data$acuity, ref="Yes")
#setup control function for resampling and binary classification performance
#using 10 fold cross validation
ctrl <- trainControl(method = "cv", number=10, summaryFunction=twoClassSummary,
classProbs=T, savePredictions=T) #saving predictions from each resample fold
# logistic regression
set.seed(199)
d.log <-  train(data ~ ., data=d.train, method="glm", family="binomial", metric="ROC", trControl=ctrl)
######### analyses #########
# split data into training and test set
# training set = .7
set.seed(199)
trainIndex <- createDataPartition(data$acuity, p = .7, list=F)
train_data <- data[trainIndex,]
test_data <- data[-trainIndex,]
# checking for imbalances
d.table<- table(data$acuity)
prop.table(d.table)
#setup control function for resampling and binary classification performance
#using 10 fold cross validation
ctrl <- trainControl(method = "cv", number=10, summaryFunction=twoClassSummary,
classProbs=T, savePredictions=T) #saving predictions from each resample fold
# logistic regression
set.seed(199)
d.log <-  train(data ~ ., data=train_data, method="glm", family="binomial", metric="ROC", trControl=ctrl)
data(Default)
str(Default)
#these data are unbalanced
d.table<- table(Default$default)
#converting to factors to dummy codes
#including DV because it should be a binary value too
default.dmodel <- dummyVars(~student + balance + income, data=Default, fullRank=T)
Default.d <- as.data.frame(predict(default.dmodel, Default))
Default.d$default <- Default$default #copy back DV
#creating test and training set as example
#if dataset is not very big avoid train/test splits high variation
#going use carets partition function to randomly split 70% of training set values
#proportional to class balance
set.seed(199)
trainIndex <- createDataPartition(Default.d$default, p=.7, list=F)
d.train <- Default.d[trainIndex,]
d.test <- Default.d[-trainIndex,]
#setup control function for resampling and binary classification performance
#using 10 fold cross validation
ctrl <- trainControl(method = "cv", number=10, summaryFunction=twoClassSummary,
classProbs=T, savePredictions=T) #saving predictions from each resample fold
##logistic regression
set.seed(199)#ALWAYS USE same SEED ACROSS trains to ensure identical cv folds
d.log <-  train(default ~ ., data=d.train, method="glm", family="binomial", metric="ROC", trControl=ctrl)
typeof(d.train)
d.train
train_data
data(Default)
View(data(Default))
View(Default)
# replace binary values with yes or no in acuity
data1 <- replace(data$acuity, data$acuity=0, "No")
?gsub
?gsub
# simple additive logistic regression
default_glm_method = train(
form=data~.,
data=train_data,
trControl=trainControl(method="cv", number=5),
method="glm",
family="binomial"
)
?model.frame.default
typeof(data)
typeof(train_data)
typeof(d.train)
View(default)
data(Default)
str(Default)
#these data are unbalanced
d.table<- table(Default$default)
#lets relevel the Default factor so Yes becomes the Positive class by default (Sensitivity)
Default$default <- relevel(Default$default, ref="Yes")
#converting to factors to dummy codes
#including DV because it should be a binary value too
default.dmodel <- dummyVars(~student + balance + income, data=Default, fullRank=T)
Default.d <- as.data.frame(predict(default.dmodel, Default))
Default.d$default <- Default$default #copy back DV
View(Default)
typeof(Default)
str(Default)
str(data)
?rep
?replace
?factor
?gsub
?replace
# simple additive logistic regression
default_glm_method = train(
form=data~.,
data=train_data,
trControl=trainControl(method="cv", number=5),
method="glm",
family="binomial"
)
?model.frame.defaul
?model.frame.default
d1 <- as.data.frame(data)
d1
d1 <- as.data.frame(train_data)
d1
# simple additive logistic regression
default_glm_method = train(
form=data~.,
data=d1,
trControl=trainControl(method="cv", number=5),
method="glm",
family="binomial"
)
typeof(d1)
# simple additive logistic regression
default_glm_method = train(
form=data~.,
data=train_data,
trControl=trainControl(method="cv", number=5),
method="glm",
family="binomial"
)
# simple additive logistic regression
default_glm_method = train(
formula=data~.,
data=train_data,
trControl=trainControl(method="cv", number=5),
method="glm",
family="binomial"
)
default_glm_method
#setup control function for resampling and binary classification performance
#using 10 fold cross validation
ctrl <- trainControl(method = "cv", number=10, summaryFunction=twoClassSummary,
classProbs=T, savePredictions=T) #saving predictions from each resample fold
# simple additive logistic regression
set.seed(199)
default_glm_method = train(data ~ ., data=train_data, method="glm", family="binomial", metric="ROC", trControl=ctrl)
default_glm_method = train(data ~ ., data=unlist(train_data), method="glm", family="binomial", metric="ROC", trControl=ctrl)
default_glm_method = train(data ~ ., data=list(train_data), method="glm", family="binomial", metric="ROC", trControl=ctrl)
data
colnames(df)
colnames(data)
colnames(train_data)
default_glm_method = train(data ~ ., data=data.frame(train_data), method="glm", family="binomial", metric="ROC", trControl=ctrl)
default_glm_method = train(data ~ ., data=list(train_data), method="glm", family="binomial", metric="ROC", trControl=ctrl)
?relevel
data(Default)
str(Default)
?data
#these data are unbalanced
d.table<- table(Default$default)
#lets relevel the Default factor so Yes becomes the Positive class by default (Sensitivity)
Default$default <- relevel(Default$default, ref="Yes")
data(Default)
str(Default)
Default
head(Default)
#converting to factors to dummy codes
#including DV because it should be a binary value too
default.dmodel <- dummyVars(~student + balance + income, data=Default, fullRank=T)
Default.d <- as.data.frame(predict(default.dmodel, Default))
Default.d$default <- Default$default #copy back DV
head(Default.d)
#creating test and training set as example
#if dataset is not very big avoid train/test splits high variation
#going use carets partition function to randomly split 70% of training set values
#proportional to class balance
set.seed(199)
trainIndex <- createDataPartition(Default.d$default, p=.7, list=F)
d.train <- Default.d[trainIndex,]
d.test <- Default.d[-trainIndex,]
#setup control function for resampling and binary classification performance
#using 10 fold cross validation
ctrl <- trainControl(method = "cv", number=10, summaryFunction=twoClassSummary,
classProbs=T, savePredictions=T) #saving predictions from each resample fold
##logistic regression
set.seed(199)#ALWAYS USE same SEED ACROSS trains to ensure identical cv folds
d.log <-  train(default ~ ., data=d.train, method="glm", family="binomial", metric="ROC", trControl=ctrl)
summary(d.log)
data <- read.csv("~/PycharmProjects/bda_594/BDA594-Group10/cleaned_data.csv", header=TRUE)
df <- data
colnames(df)
dim(df)
# remove first column
data <- data[-1]
colnames(data)
df <- data
########## remove outliers from predictors ##########
# remove temp < 75 or > 108
temp_range <- (75:108)
data <- subset(data, data$temperature %in% temp_range)
# remove resprate > 100 or < 10
resp_rate <- (10:100)
data <- subset(data, data$resprate %in% resp_rate)
# remove O2 state below 60
o2_rate <- (60:1000)
data <- subset(data, data$o2sat %in% o2_rate)
# remove pain levels outside of 0-10 range
pain_range <- (0:10)
data <- subset(data, data$pain %in% pain_range)
# compare descriptive stats before and after
summary(df) # original dataset
summary(data)
total_rows = dim(df[1]) - dim(data[1])
total_rows <- total_rows[1]
total_rows
######### analyses #########
# split data into training and test set
# training set = .7
set.seed(199)
trainIndex <- createDataPartition(data$acuity, p = .7, list=F)
train_data <- data[trainIndex,]
test_data <- data[-trainIndex,]
# checking for imbalances
d.table<- table(data$acuity)
prop.table(d.table)
#setup control function for resampling and binary classification performance
#using 10 fold cross validation
ctrl <- trainControl(method = "cv", number=10, summaryFunction=twoClassSummary,
classProbs=T, savePredictions=T) #saving predictions from each resample fold
# simple additive logistic regression
set.seed(199)
default_glm_method = train(data ~ ., data=list(train_data), method="glm", family="binomial", metric="ROC", trControl=ctrl)
default_glm_method = train(data ~ ., data=train_data, method="glm", family="binomial", metric="ROC", trControl=ctrl)
typeof(Default)
typeof(data)
Default
head(Default)
head(data)
d.lda <-  train(data ~ ., data=train_data, method="lda", metric="ROC", trControl=ctrl)
# replace values on acuity column with yes or no........
data$acuity[data$acuity == 0] <- "No"
data
data$acuity[data$acuity == 1] <- "Yes"
# checking for imbalances
d.table<- table(data$acuity)
prop.table(d.table)
#setup control function for resampling and binary classification performance
#using 10 fold cross validation
ctrl <- trainControl(method = "cv", number=10, summaryFunction=twoClassSummary,
classProbs=T, savePredictions=T) #saving predictions from each resample fold
# simple additive logistic regression
set.seed(199)
default_glm_method = train(data ~ ., data=train_data, method="glm", family="binomial", metric="ROC", trControl=ctrl)
str(data)
?as.factor
# create factor of 2 levels
as.factor(data$acuity, levels=2)
# create factor of 2 levels
as.factor(data$acuity)
data
str(data)
str(Default)
typeof(data$acuity)
# create factor of 2 levels
data$acuity <- as.factor(data$acuity)
str(data)
set.seed(199)
trainIndex <- createDataPartition(data$acuity, p = .7, list=F)
train_data <- data[trainIndex,]
test_data <- data[-trainIndex,]
# checking for imbalances
d.table<- table(data$acuity)
prop.table(d.table)
#setup control function for resampling and binary classification performance
#using 10 fold cross validation
ctrl <- trainControl(method = "cv", number=10, summaryFunction=twoClassSummary,
classProbs=T, savePredictions=T) #saving predictions from each resample fold
# simple additive logistic regression
set.seed(199)
default_glm_method = train(data ~ ., data=train_data, method="glm", family="binomial", metric="ROC", trControl=ctrl)
default_glm_method = train(data ~ ., data=list(train_data), method="glm", family="binomial", metric="ROC", trControl=ctrl)
str(data)
str(train_data)
default_glm_method = train(data ~ ., train_data, method="glm", family="binomial", metric="ROC", trControl=ctrl)
?glm
mylogit <- gml(data ~ ., family="binomial", data=train_data)
mylogit <- glm(data ~ ., family="binomial", data=train_data)
str(Default)
str(data)
str(train_data)
data(Default, package="ISLR")
library(caret)
set.seed(430)
data(Default, package="ISLR")
library(caret)
set.seed(430)
default_idx = createDataPartition(Default$default, p=.75, list=F)
default_trn = Default[default_idx,]
default_tst = Default[-default_idx,]
str(default)
?train
?train
str(default)
default_glm_method = train(default ~ ., train_data, method="glm", family="binomial", metric="ROC", trControl=ctrl)
str(default.dmodel)
default_glm_method = train(acuity ~ ., train_data, method="glm", family="binomial", metric="ROC", trControl=ctrl)
summary(default_glm_method)
varImp(default_glm_method)
?varImp
